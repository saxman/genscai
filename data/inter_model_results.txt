loading model: meta-llama/Meta-Llama-3.1-8B-Instruct
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:02<00:00,  1.90it/s]
testing prompt: ..................................................................
prompt: ollama:llama3.2:3b, model: meta-llama/Meta-Llama-3.1-8B-Instruct, metrics: {'accuracy': 0.8939393939393939, 'precision': 1.0, 'recall': 0.8478260869565217}
testing prompt: ..................................................................
prompt: ollama:llama3.1:8b, model: meta-llama/Meta-Llama-3.1-8B-Instruct, metrics: {'accuracy': 0.9696969696969697, 'precision': 0.9583333333333334, 'recall': 1.0}
testing prompt: ..................................................................
prompt: meta-llama/Meta-Llama-3.1-8B-Instruct, model: meta-llama/Meta-Llama-3.1-8B-Instruct, metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0}
testing prompt: ..................................................................
prompt: microsoft/phi-4, model: meta-llama/Meta-Llama-3.1-8B-Instruct, metrics: {'accuracy': 0.9696969696969697, 'precision': 1.0, 'recall': 0.9565217391304348}
testing prompt: ..................................................................
prompt: google/gemma-2-9b-it, model: meta-llama/Meta-Llama-3.1-8B-Instruct, metrics: {'accuracy': 0.9393939393939394, 'precision': 1.0, 'recall': 0.9130434782608695}
testing prompt: ..................................................................
prompt: mistralai/Mistral-Nemo-Instruct-2407, model: meta-llama/Meta-Llama-3.1-8B-Instruct, metrics: {'accuracy': 0.9545454545454546, 'precision': 0.9777777777777777, 'recall': 0.9565217391304348}
testing prompt: ..................................................................
prompt: openai:gpt-4o-mini, model: meta-llama/Meta-Llama-3.1-8B-Instruct, metrics: {'accuracy': 0.9848484848484849, 'precision': 1.0, 'recall': 0.9782608695652174}
testing prompt: ..................................................................
prompt: openai:gpt-4o, model: meta-llama/Meta-Llama-3.1-8B-Instruct, metrics: {'accuracy': 0.9848484848484849, 'precision': 1.0, 'recall': 0.9782608695652174}
emptying cuda cache
loading model: microsoft/phi-4
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:11<00:00,  1.94s/it]
testing prompt: ..................................................................
prompt: ollama:llama3.2:3b, model: microsoft/phi-4, metrics: {'accuracy': 0.8333333333333334, 'precision': 1.0, 'recall': 0.7608695652173914}
testing prompt: ..................................................................
prompt: ollama:llama3.1:8b, model: microsoft/phi-4, metrics: {'accuracy': 0.9848484848484849, 'precision': 0.9787234042553191, 'recall': 1.0}
testing prompt: ..................................................................
prompt: meta-llama/Meta-Llama-3.1-8B-Instruct, model: microsoft/phi-4, metrics: {'accuracy': 0.9848484848484849, 'precision': 1.0, 'recall': 0.9782608695652174}
testing prompt: ..................................................................
prompt: microsoft/phi-4, model: microsoft/phi-4, metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0}
testing prompt: ..................................................................
prompt: google/gemma-2-9b-it, model: microsoft/phi-4, metrics: {'accuracy': 0.9545454545454546, 'precision': 1.0, 'recall': 0.9347826086956522}
testing prompt: ..................................................................
prompt: mistralai/Mistral-Nemo-Instruct-2407, model: microsoft/phi-4, metrics: {'accuracy': 0.9696969696969697, 'precision': 0.9782608695652174, 'recall': 0.9782608695652174}
testing prompt: ..................................................................
prompt: openai:gpt-4o-mini, model: microsoft/phi-4, metrics: {'accuracy': 0.9848484848484849, 'precision': 0.9787234042553191, 'recall': 1.0}
testing prompt: ..................................................................
prompt: openai:gpt-4o, model: microsoft/phi-4, metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0}
emptying cuda cache
loading model: google/gemma-2-9b-it
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:11<00:00,  2.87s/it]
testing prompt: ..................................................................
prompt: ollama:llama3.2:3b, model: google/gemma-2-9b-it, metrics: {'accuracy': 0.9242424242424242, 'precision': 1.0, 'recall': 0.8913043478260869}
testing prompt: ..................................................................
prompt: ollama:llama3.1:8b, model: google/gemma-2-9b-it, metrics: {'accuracy': 0.9545454545454546, 'precision': 0.9777777777777777, 'recall': 0.9565217391304348}
testing prompt: ..................................................................
prompt: meta-llama/Meta-Llama-3.1-8B-Instruct, model: google/gemma-2-9b-it, metrics: {'accuracy': 0.9848484848484849, 'precision': 1.0, 'recall': 0.9782608695652174}
testing prompt: ..................................................................
prompt: microsoft/phi-4, model: google/gemma-2-9b-it, metrics: {'accuracy': 0.9848484848484849, 'precision': 1.0, 'recall': 0.9782608695652174}
testing prompt: ..................................................................
prompt: google/gemma-2-9b-it, model: google/gemma-2-9b-it, metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0}
testing prompt: ..................................................................
prompt: mistralai/Mistral-Nemo-Instruct-2407, model: google/gemma-2-9b-it, metrics: {'accuracy': 0.9393939393939394, 'precision': 0.9565217391304348, 'recall': 0.9565217391304348}
testing prompt: ..................................................................
prompt: openai:gpt-4o-mini, model: google/gemma-2-9b-it, metrics: {'accuracy': 0.9848484848484849, 'precision': 0.9787234042553191, 'recall': 1.0}
testing prompt: ..................................................................
prompt: openai:gpt-4o, model: google/gemma-2-9b-it, metrics: {'accuracy': 0.9696969696969697, 'precision': 1.0, 'recall': 0.9565217391304348}
emptying cuda cache
loading model: mistralai/Mistral-Nemo-Instruct-2407
Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:14<00:00,  2.81s/it]
testing prompt: ..................................................................
prompt: ollama:llama3.2:3b, model: mistralai/Mistral-Nemo-Instruct-2407, metrics: {'accuracy': 0.7575757575757576, 'precision': 1.0, 'recall': 0.6521739130434783}
testing prompt: ..................................................................
prompt: ollama:llama3.1:8b, model: mistralai/Mistral-Nemo-Instruct-2407, metrics: {'accuracy': 0.9242424242424242, 'precision': 1.0, 'recall': 0.8913043478260869}
testing prompt: ..................................................................
prompt: meta-llama/Meta-Llama-3.1-8B-Instruct, model: mistralai/Mistral-Nemo-Instruct-2407, metrics: {'accuracy': 0.9393939393939394, 'precision': 1.0, 'recall': 0.9130434782608695}
testing prompt: ..................................................................
prompt: microsoft/phi-4, model: mistralai/Mistral-Nemo-Instruct-2407, metrics: {'accuracy': 0.9393939393939394, 'precision': 1.0, 'recall': 0.9130434782608695}
testing prompt: ..................................................................
prompt: google/gemma-2-9b-it, model: mistralai/Mistral-Nemo-Instruct-2407, metrics: {'accuracy': 0.9393939393939394, 'precision': 1.0, 'recall': 0.9130434782608695}
testing prompt: ..................................................................
prompt: mistralai/Mistral-Nemo-Instruct-2407, model: mistralai/Mistral-Nemo-Instruct-2407, metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0}
testing prompt: ..................................................................
prompt: openai:gpt-4o-mini, model: mistralai/Mistral-Nemo-Instruct-2407, metrics: {'accuracy': 0.9848484848484849, 'precision': 0.9787234042553191, 'recall': 1.0}
testing prompt: ..................................................................
prompt: openai:gpt-4o, model: mistralai/Mistral-Nemo-Instruct-2407, metrics: {'accuracy': 0.9696969696969697, 'precision': 1.0, 'recall': 0.9565217391304348}
emptying cuda cache
loading model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B
Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:10<00:00,  5.15s/it]
classifying: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [08:16<00:00,  7.52s/it]
prompt: ollama:llama3.2:3b, model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B, metrics: {'accuracy': 0.9090909090909091, 'precision': 1.0, 'recall': 0.8695652173913043}
classifying: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [07:40<00:00,  6.98s/it]
prompt: ollama:llama3.1:8b, model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B, metrics: {'accuracy': 0.9242424242424242, 'precision': 0.9767441860465116, 'recall': 0.9130434782608695}
classifying: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [08:38<00:00,  7.85s/it]
prompt: meta-llama/Meta-Llama-3.1-8B-Instruct, model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B, metrics: {'accuracy': 0.9242424242424242, 'precision': 0.9767441860465116, 'recall': 0.9130434782608695}
classifying: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [09:28<00:00,  8.62s/it]
prompt: microsoft/phi-4, model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B, metrics: {'accuracy': 0.9242424242424242, 'precision': 1.0, 'recall': 0.8913043478260869}
classifying: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [09:36<00:00,  8.74s/it]
prompt: google/gemma-2-9b-it, model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B, metrics: {'accuracy': 0.9393939393939394, 'precision': 0.9772727272727273, 'recall': 0.9347826086956522}
classifying: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [07:19<00:00,  6.66s/it]
prompt: mistralai/Mistral-Nemo-Instruct-2407, model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B, metrics: {'accuracy': 0.9545454545454546, 'precision': 0.9777777777777777, 'recall': 0.9565217391304348}
classifying: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [09:11<00:00,  8.35s/it]
prompt: openai:gpt-4o-mini, model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B, metrics: {'accuracy': 0.8787878787878788, 'precision': 0.975, 'recall': 0.8478260869565217}
classifying: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [08:51<00:00,  8.05s/it]
prompt: openai:gpt-4o, model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B, metrics: {'accuracy': 0.8939393939393939, 'precision': 0.975609756097561, 'recall': 0.8695652173913043}
classifying: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [09:45<00:00,  8.87s/it]
prompt: google/gemma-3-12b-it, model: deepseek-ai/DeepSeek-R1-Distill-Llama-8B, metrics: {'accuracy': 0.9242424242424242, 'precision': 1.0, 'recall': 0.8913043478260869}
emptying cuda cache