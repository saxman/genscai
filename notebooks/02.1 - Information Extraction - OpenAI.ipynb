{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02.1 - Information Extraction using OpenAI\n",
    "\n",
    "In this notebook, we explore ways that OpenAI LLMs can be used for extracting information relevant to infections disease modeling, such as categorical keywords (e.g. diseases, treatments, populations, etc.), from publication titles/abstracts. This information will be used later for publication search, clustering, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from genscai import paths\n",
    "\n",
    "dotenv.load_dotenv(paths.root / \"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the publications from the database, skipping any publications without abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from genscai import paths\n",
    "\n",
    "with open(paths.data / \"training_modeling_papers.json\", \"r\") as f:\n",
    "    papers = json.load(f)\n",
    "\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORD_PROMPT_TEMPLATE = \"\"\"\n",
    "Your goal is to identify important keywords in scientific paper abstracts.\n",
    "For the abstract below, identify all diseases, treatments, interventions, and vectors mentioned.\n",
    "List the keywords identified in a JSON array, with each item in the array including keyword_type and value.\n",
    "The only valid keyword types are disease, treatment, intervention, and vector.\n",
    "Only return the JSON array.\n",
    "\n",
    "abstract:\n",
    "{abstract}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "article = papers[0]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": KEYWORD_PROMPT_TEMPLATE.format(abstract=article[\"abstract\"]),\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Structured Ouptuts: https://platform.openai.com/docs/guides/structured-outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Keyword(BaseModel):\n",
    "    type: str\n",
    "    value: str\n",
    "\n",
    "\n",
    "class KeywordResults(BaseModel):\n",
    "    keywords: list[Keyword]\n",
    "\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        # {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": KEYWORD_PROMPT_TEMPLATE.format(abstract=article[\"abstract\"]),\n",
    "        }\n",
    "    ],\n",
    "    response_format=KeywordResults,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSIFICATION_PROMPT_TEMPLATE = \"\"\"\n",
    "Given the following scientific publication abstract,\n",
    "identify if the publication references an infectious disease modeling technique.\n",
    "Only return YES or NO.\n",
    "If YES, also return the name of the tecnhique or techniques used.\n",
    "\n",
    "abstract:\n",
    "{abstract}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in papers[5:10]:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": MODEL_CLASSIFICATION_PROMPT_TEMPLATE.format(abstract=paper[\"abstract\"]),\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    print(paper[\"abstract\"])\n",
    "    print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
